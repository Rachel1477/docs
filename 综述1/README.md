# 关于3D物体检测和6D姿态估计的综述
## 1.两者任务的本质区别
>**3D物体检测**：主要目的是 识别并定位物体在三维空间中的位置。具体来说，它不仅要检测物体的存在，还要估计物体的位置和尺寸  
**输出**：输出一个三维边界框，定义了物体在三维空间中的位置和尺寸。

>**6D姿态估计**:主要目标是 确定物体的姿态，即物体在三维空间中的 旋转（3D旋转）和位移（3D平移）  
**输出**：物体的 旋转矩阵或四元数（表示物体的方向）和 位移向量（表示物体的位置）。

## 2.3D物体检测的困难
本文只提到了3D物体检测的困难，但是6D姿态估计在很大程度上与3D物体检测重合，因此两者面临的困难是共有的。

为了检测3D物体并推测其姿态，我们需要完全理解图像，而不仅仅是知道图像的分类或定位。但是在实现物体识别和定位任务时存在一些重要的障碍，如

（1）.背景和环境的影响：**遮挡**、**混乱的环境**、**光照条件**

（2）.对于精度和准度的要求：我们需要找到一张图片里**正确的部分**（准度）并且**更加精确地识别**（3D/2D）物体（精度）

（3）.处理任何给定的图像可能包含多个物体：这些物体位于图像的不同位置，由于测试窗口的数量庞大，过程**相对昂贵**且会**产生额外的窗口**。此外，如果应用某些稳定的滑动窗口模板，它会创建不满意的区域。

（4）.大小差异和视角：对于一张图片中的物体，是 **“体积小”** 还是 **“距离远”** 的问题

>传统的3D物体检测模型流程：信息区域选择->特征提取->分类。

## 简单介绍大领域
## 1.人工神经网络（ANN）
人工神经网络（ANN）的功能与人类大脑的功能几乎相同，因为知识是通过网络在学习过程中获取的，并通过某些突触权重神经元进行存储。为了实现最终的设计目标并改变网络的突触权重，ANN实现了一种称为学习算法的学习过程。
## 2.深度神经网络（DNN）
通过应用多层网络从原始数据中提取高级特征。例如，在图像处理中，深度学习模型的较低层只能识别边缘，而较高层可以检测某些字母、物体或物体的特征。最终，深度学习可以处理无序/有序、标记或未标记的数据，并构建模式以进行更准确的预测 
## 3.卷积神经网络及其变体
卷积神经网络（CNN）具有深度前馈架构，并且具有显著的泛化能力，可以通过全连接层构建更好的网络。CNN 的两个最显著特点是其**分类组合能力**和从图像中**提取强大特征**的能力，这证明了 CNN 是最强大的目标检测分类器之一。
一下为常见的CNN基础模型：
>ImageNet 、AlexNet 、ConvNet、LeNet、VGGNet、ResNet 、ZFNet 、GoogLeNet 、GPU处理器的大规模分布式集群 、 OverFeat

针对越来越刁钻的任务，传统的CNN被改变以适应不同的任务
### 3-1.基于区域的卷积神经网络（R-CNN）
R-CNN 通过结合选择性搜索（Selective Search, SS）算法和卷积神经网络（CNN）来有效地进行物体检测。解决了**传统方法在物体检测任务中的精度和效率问题**。R-CNN 主要应用于图像中的物体识别任务，其核心思想是**从图像中提取多个候选区域**，然后对每个区域**分别应用 CNN**进行分类。
### 3-2.Fast R-CNN
通过共享卷积核和RoI池化技术，显著加速了R-CNN的物体检测速度
### 3-3.Faster R-CNN
完全舍弃了选择性搜索算法，允许网络**自主学习对于目标区域的搜索**。并通过预测边界框的交并比（IoU，Intersection-over-Union）衡量区域搜索的好坏，得到比Fast R-CNN更快的检测速度
### 3-4.Mask R-CNN
是 Faster R-CNN 的实际扩展，通过在原有的结构中增加一个额外的分支来预测物体掩码（掩码是一个二值图像--即只有 0 和 1 的图像，其中的 "1" 表示图像中的某个区域或物体，而 "0" 表示背景或不感兴趣的区域。），**这是一个像素级别的操作。**
### 3-5.YOLO
大学生水毕设神器，它的理念就是**只需要一次前向传播**，与在这之前的所有实现都不同。yolo经过多次迭代，其功能日益强大。yolo最大的特点就是**检测速度超级超级快**。使用它，你只要download然后load_model就可以了，超级方便，超级能水毕设
### 3-6.单次多框检测器 (SSD)
一种用于多个区域检测的单次检测器。它在图像上应用额外的小型卷积滤波器，速度更快，且比YOLO更加准确。
### 3-7.Mesh R-CNN
Facebook 提出了一个新颖的 RCNN 方法，称为 Mesh R-CNN，该方法能够将 2D 物体转换为 3D 形状和网格。Facebook 强调了其最新的进展，能够识别复杂的问题。该研究应用了深度学习技术来理解复杂物体的 3D 形状，并提出了新的架构，如边界框、3D体素模式、点云和消息传递，用于预测和定位。是**行业奠基之作**

## 4.一些子任务和解决它们的方法
### 4-1.特征提取、分割与匹配
#### 一.SIFT（尺度不变特征变换）
是一种用于检测和描述图像**局部特征**的计算机视觉算法。通过将图像转换为大量的局部特征向量，SIFT 每次处理一张图像时可生成约 1000 个 SIFT 关键点，并在 1k 毫秒内完成分类。即使图像中存在遮挡，SIFT 依然能够提供高精度的识别结果。
#### 二.DaSNetV2
该方法通过采用 PWP 3D (每像素计数) 方法并利用 NVIDIA CUDA 框架加速推理
#### 三.DORN
一个多尺度网络框架，采用间距递增离散化 (SID) 策略重建深度和深度网络，从而减少了现有特征图的复杂性。

### 4-2.形状变化
#### 一. 3DVP (3D Voxel Pattern)
该方法使用 ACF (Aggregate Channel Features) 检测器来提取每个对象的基本特征
#### 二. C3DPO (Canonical 3D Pose) 网络
该网络可以从单色 RGB 图像中部分重建 3D 对象，从而实现视角变换和对象变形,即便没有训练图像和网格数据
#### 三.Deep MANTA 的框架
Deep MANTA 的核心思想是利用深度卷积神经网络（CNN）来学习和提取目标的多视角几何特征，从而同时完成多个任务。通过端到端的学习框架
#### 四.CenterNet 框架
该框架比传统的边界框检测器和姿态估计方法更简单、更快且更准确。

### 4-3.3D 边界框顶点的 3D 投影
3D 边界框顶点的 3D 投影是指将 3D 边界框的顶点投影到 2D 平面（通常是相机的图像平面）上，以便在 2D 空间中可视化或处理它们的过程。此过程对于对象检测、跟踪和增强现实等应用程序至关重要
#### 一.3DOP (3D Object Proposal)
3DOP 的主要贡献是：
- 利用**深度信息**提升候选区域的精确度。
- 为物体检测提供更可靠的 3D proposals，从而提高后续分类和姿态估计的性能。
- 克服传统 2D region proposal 方法在 3D 场景中的局限性。

3DOP 生成多组 3D 候选框，能够识别 3D 空间中几乎所有对象。该方法引入了对象尺寸、地面平面、深度、多样的空间点密度、框内点密度、可见性及与地面的距离等特征。

#### 二.Mono3D 
Mono3D的主要贡献：
- 不依赖深度图或LiDAR数据，成本更低。
- 通过语义分割增强候选框生成的准确性，提升检测效果。
- 效率较高，虽然不如点云方法精确，但推理速度快




